import pandas as pd
import numpy as np
from collections import Counter
from eunjeon import Mecab

# 1. ë°ì´í„° ë¡œë”© ë° ì •ì œ
df = pd.read_table('steam.txt', names=['label', 'reviews'])
df.drop_duplicates(subset=['reviews'], inplace=True)
df.dropna(how='any', inplace=True)

# 2. í˜•íƒœì†Œ ë¶„ì„ + ë¶ˆìš©ì–´ ì œê±°
mecab = Mecab()
stopwords = ['ë„', 'ëŠ”', 'ë‹¤', 'ì˜', 'ê°€', 'ì´', 'ì€', 'í•œ', 'ì—', 'í•˜', 'ê³ ', 'ì„', 'ë¥¼',
             'ì¸', 'ë“¯', 'ê³¼', 'ì™€', 'ë„¤', 'ë“¤', 'ì§€', 'ì„', 'ê²Œ', 'ë§Œ', 'ê²Œì„',
             'ê²œ', 'ë˜', 'ìŒ', 'ë©´', 'ì—ì„œ', 'ë‹ˆê¹Œ', 'ì–´ìš”', 'ë‹ˆë‹¤']

df['reviews'] = df['reviews'].str.replace("[^ã„±-ã…ã…-ã…£ê°€-í£ ]", "", regex=True)
df['tokenized'] = df['reviews'].apply(lambda x: [t for t in mecab.morphs(x) if t not in stopwords])

# 3. ê¸ì •/ë¶€ì • ë‹¨ì–´ Counter
positive_words = np.hstack(df[df['label'] == 1]['tokenized'].values)
negative_words = np.hstack(df[df['label'] == 0]['tokenized'].values)

# 1. ì–‘ìª½ word count
positive_word_count = Counter(positive_words)
negative_word_count = Counter(negative_words)

# 2. ëª¨ë“  ë‹¨ì–´ ì§‘í•©
all_words = set(positive_word_count.keys()) | set(negative_word_count.keys())

# 3. ë¹„ìœ¨ ê¸°ë°˜ ê¸/ë¶€ì • ë‹¨ì–´ ì„ íƒ
positive_vocab = set()
negative_vocab = set()
min_count = 3  # ë„ˆë¬´ ë†’ìœ¼ë©´ ë‹¤ ì‚¬ë¼ì§

for word in all_words:
    pos = positive_word_count[word]
    neg = negative_word_count[word]
    total = pos + neg
    if total < min_count:
        continue
    ratio = pos / total
    if ratio > 0.75:
        positive_vocab.add(word)
    elif ratio < 0.25:
        negative_vocab.add(word)


#print(" ë¶€ì • ë‹¨ì–´ TOP20:", negative_word_count.most_common(20))
#print(" ê¸ì • ë‹¨ì–´ TOP20:", positive_word_count.most_common(20))


# 5. ê°ì„± ì ìˆ˜ ë¶„ë¥˜ í•¨ìˆ˜ ì •ì˜
def classify_sentiment(tokens, pos_words, neg_words):
    pos_count = sum(1 for word in tokens if word in pos_words)
    neg_count = sum(1 for word in tokens if word in neg_words)
    total = pos_count + neg_count

    if total == 0:
        return 2  # ì¤‘ë¦½

    ratio = pos_count / total

    # ë” ì™„í™”ëœ ê¸°ì¤€
    if ratio >= 0.75:
        return 4  # ì•„ì£¼ ê¸ì •
    elif ratio >= 0.55:
        return 3  # ê¸ì •
    elif ratio >= 0.45:
        return 2  # ì¤‘ë¦½
    elif ratio >= 0.25:
        return 1  # ë¶€ì •
    else:
        return 0  # ì•„ì£¼ ë¶€ì •


# 6. ì‹¤ì œ ê°ì„± ì ìˆ˜ ì ìš©
df['new_label'] = df['tokenized'].apply(lambda x: classify_sentiment(x, positive_vocab, negative_vocab))


for idx in range(10):
    tokens = df['tokenized'].iloc[idx]
    pos_count = sum(1 for word in tokens if word in positive_vocab)
    neg_count = sum(1 for word in tokens if word in negative_vocab)
    print(f"[{idx}] ë¦¬ë·°: {df['reviews'].iloc[idx]}")
    print(f"  í† í°: {tokens}")
    print(f"  ê¸ì • ë‹¨ì–´ ìˆ˜: {pos_count}, ë¶€ì • ë‹¨ì–´ ìˆ˜: {neg_count}")
    print(f"  -> ê°ì„± ì ìˆ˜: {classify_sentiment(tokens, positive_vocab, negative_vocab)}\n")


# 7. ê°ì„± ì ìˆ˜ ë¶„í¬ í™•ì¸
print("\nğŸ¯ ê°ì„± ì ìˆ˜ ë¶„í¬ (0~4):")
print(df['new_label'].value_counts().sort_index())

# 8. ì €ì¥
df[['new_label', 'reviews']].to_csv('steam_5class.txt', sep='\t', index=False, header=False)
print("âœ… steam_5class.txt íŒŒì¼ ìƒì„± ì™„ë£Œ!")